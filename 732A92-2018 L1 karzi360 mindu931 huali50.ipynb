{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Students:__ mindu931, karzi360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Overall idea:\n",
    " 1. Crawling webpage of overview to get source code of overview webpage (=content)\n",
    " 2. From this long source code information from source code of overview page, get all the \n",
    " available linked apps (since identifier = url of the link = url of the app detail page itself,\n",
    " finding all the identifiers following one specific pattern is sufficient) (=appreg = regular\n",
    " expression for finding the app-url identfiers; app_url_list = (unique) list of the detected\n",
    " app-urls satisfying the pattern)\n",
    " 3. Now accessing each app-url individually and looking in the corresponding detail page\n",
    " source code for the description of the app --> accessable by another pattern (=desc_container)\n",
    " 4. All description information + additional pattern information is stored, but needs to be\n",
    " cleaned for data preprocessing (<html>... information not important for text mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Get the webpage content by using functions in \n",
    "__[urllib module](https://docs.python.org/3/library/urllib.html#module-urllib)__.\n",
    "\n",
    "b) Get app url by regular expression using functions from __[re module](https://docs.python.org/3/library/re.html?highlight=re#module-re)__.\n",
    "\n",
    "The code block below will run both a and b part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "appreg = r'href=\\\"(/store/apps/details.*?)\\\"'\n",
    "appre = re.compile(appreg)\n",
    "\n",
    "all_list = []\n",
    "url = 'https://play.google.com/store/apps/category/GAME?hl=en'\n",
    "content = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "app_url_list = re.findall(appre,content)\n",
    "app_url_list = list(set(app_url_list))\n",
    "#print(app_url_list)\n",
    "#print(len(app_url_list))\n",
    "all_list.extend(app_url_list)\n",
    "        \n",
    "print(len(all_list))\n",
    "#print(all_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Access specific webpage to get description of each app and then store the description in files.\n",
    "\n",
    "Now, we will go throught each url to get the description and app name. We create a file for each app, with tittle of the file is the name of the app. List of all apps is saved in the \"files\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of apps that crawled\n",
      "Dr  Driving\n",
      "Block Craft 3D  Building Simulator Games For Free\n",
      "Chess\n",
      "Puzzle Game\n",
      "Subway Surfers\n",
      "Pou\n",
      "Farming Simulator 18\n",
      "Dedi App 17\n",
      "Traffic Rider\n",
      "Beach Buggy Racing\n",
      "True Skate\n",
      "Stickman Skate Battle\n",
      "City Skater   Rule the Skate Park \n",
      "Stickman Soccer 2018\n",
      "Jet Car Stunts 2\n",
      "Dr  Driving 2\n",
      "Bike Race Free   Top Motorcycle Racing Games\n",
      "Traffic Racer\n",
      "FIFA Soccer\n",
      "Merge Plane   Click   Idle Tycoon\n",
      "Asphalt 8  Airborne\n",
      "Asphalt Nitro\n",
      "Real Chess\n",
      "Real Checkers\n",
      "Real Checkers\n",
      "Chess Online\n",
      "Russian Checkers\n",
      "Spanish Checkers\n",
      "English to Hindi Dictionary\n",
      "English to Hindi Dictionary\n",
      "Brazilian Checkers\n",
      "eBook Reader   Your Free audio eBook Library\n",
      "Checkers\n",
      "Checkers\n",
      "Checkers Free\n",
      "Sudoku\n",
      "Sudoku\n",
      "Tic Tac Toe Free\n",
      "English Hindi Dictionary\n",
      "English Hindi Dictionary\n",
      "Dictionary   Merriam Webster\n",
      "Pocket Thesaurus\n",
      "Pocket Quotations Premium\n",
      "Learner s Dictionary   English\n",
      "WordReference com dictionaries\n",
      "English French Thesaurus\n",
      "POC Bible  Malayalam \n",
      "Take Off\n",
      "Jesus Youth Prayer\n",
      "Jesus Youth\n",
      "Tecarta Bible\n",
      "Barnabodha\n",
      "Learn Hindi through English\n",
      "Learn Hindi through Tamil\n",
      "Number of already collected descriptions: 50\n",
      "Learn Kannada through Tamil\n",
      "Bible\n",
      "Manorama Online News App   Malayala Manorama\n",
      "Manorama Online News App   Malayala Manorama\n",
      "Malayala Manorama Calendar 2018\n",
      "Mathrubhumi Calendar 2018\n",
      "Gujarat Himachal Election 2017\n",
      "Malayalam News Live  Asianet News Live TV\n",
      "Ghar Baithe paise Kamaye   Earn Money Online\n",
      "Ghar Baithe paise Kamaye   Earn Money Online\n",
      "Shabd Nidhi\n",
      "dict cc dictionary\n",
      "LEO dictionary\n",
      "German Dictionary Offline\n",
      "Spanish English Translator  Dictionary   Learning\n",
      "Learn Kannada through English\n",
      "Checkers Land Online\n",
      "TV Ecuador\n",
      "Acrobat Star Show   Show  em what you got \n",
      "Dictionary Linguee\n",
      "Doctor Fluff Pet Vet\n",
      "Operate Now  Animal Hospital\n",
      "Operate Now  Hospital\n",
      "Uphill Rush Water Park Racing\n",
      "NBA LIVE Mobile Basketball\n",
      "NBA App\n",
      "Basketball NBA Live Scores  Stats  Schedules  2019\n",
      "NBAmoji\n",
      "NBA AR Basketball  Augmented Reality Shot   Portal\n",
      "Indic Keyboard Swalekh Flip\n",
      "Indic Keyboard Swalekh Flip\n",
      "Crossy Road\n",
      "Rise Up\n",
      "Racing in Car\n",
      "Pet World   My animal shelter\n",
      "English Marathi Dictionary\n",
      "English Bangla Dictionary\n",
      "English To Bangla Dictionary\n",
      "Wings on Fire   Endless Flight\n",
      "Manorama Calendar 2018\n",
      "Star Wars   KOTOR\n",
      "Hindi Keyboard\n",
      "Skateboard Party 3 Pro\n",
      "Skateboard Party 3\n",
      "Farm Heroes Saga\n",
      "Asphalt 9  Legends   2018 s New Arcade Racing Game\n",
      "Cluefinder\n",
      "Knower Nikhil   Question papers   Free jobs alert\n",
      "Knower Nikhil   Question papers   Free jobs alert\n",
      "Duolingo  Learn Languages Free\n",
      "8 Ball Pool\n",
      "Car Driving School Simulator\n",
      "Real Tractor Farming\n",
      "Full screen incoming caller\n",
      "Number of already collected descriptions: 100\n",
      "Bangla Dictionary\n"
     ]
    }
   ],
   "source": [
    "def cleanHTML(html):\n",
    "    html = re.sub('<.*?>', ' ', html) #remove the tags\n",
    "    html = re.sub('&.*?;', ' ', html) #remove the html symbols (ex: &amp;)\n",
    "    html = re.sub('https?:\\/\\/.*?(\\s|\\'|$)', ' ', html) #remove urls\n",
    "    html = re.sub('[^\\w]', ' ', html) #remove non alpha-numeric or space characters\n",
    "    return html\n",
    "\n",
    "def get_and_clean(phrase, page):\n",
    "    content = re.findall(phrase ,page)\n",
    "    content = ''.join(content)\n",
    "    content = cleanHTML(content)\n",
    "    content = content.replace('itemprop  description', '')\n",
    "    return(content)\n",
    "\n",
    "#List files\n",
    "files = []\n",
    "print('Here is the list of apps that crawled')\n",
    "\n",
    "#Check the number of apps crawled\n",
    "while len(files) < 1000 :\n",
    "    url = all_list[0]\n",
    "    all_list = all_list[1:]\n",
    "    \n",
    "    # phrase for getting name and description\n",
    "    content_reg = \"itemprop=\\\"description.*?\\\">.*?<div jsname=\\\".*?\\\">.*?</div>\"\n",
    "    nameg = r'<title id=\\\"main-title\\\">(.*?) - Apps'\n",
    "    name_reg = re.compile(nameg)\n",
    "    \n",
    "    page = urllib.request.urlopen('https://play.google.com' + url +\"&hl=en\").read().decode('utf8')\n",
    "    \n",
    "    \n",
    "    # only proceeding, when checked page contained some name, \n",
    "    # otherwise proceed with next app on all_list\n",
    "    if re.search(name_reg, page) != None :       \n",
    "            app_name = get_and_clean(name_reg, page)\n",
    "            #print(app_name)\n",
    "\n",
    "            if app_name not in files:\n",
    "                files.append(app_name)\n",
    "                \n",
    "                # for checking loop but only after every 50th iteration\n",
    "                description = get_and_clean(content_reg, page)\n",
    "                if len(files) % 50 == 0:\n",
    "                            print(\"Number of already collected descriptions: {}\".format(len(files)))\n",
    "                        \n",
    "                temp = re.findall(appre, page) #getting new app names for next step\n",
    "                all_list = list(set(all_list + temp)) # creating new app_url_list for \n",
    "                \n",
    "                #Write the file\n",
    "                try:\n",
    "                    with open(app_name , 'w') as file:\n",
    "                            print(app_name)\n",
    "                            #print(description)\n",
    "                            file.write(description)\n",
    "                            file.close()\n",
    "                except:\n",
    "                    print(app_name) # can't write the file (character issue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Inverted file index (Vector Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Preprocess text using NLP techniques from __[nltk module](http://www.nltk.org/py-modindex.html)__ or spaCy.\n",
    "\n",
    "Using nltk.download(ID) to get the corpora if it is not downloaded before. __[nltk corpora](http://www.nltk.org/nltk_data/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Duong Minh\n",
      "[nltk_data]     Duc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will clean the descriptions of each app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of apps that cleaned\n",
      "Dr  Driving\n",
      "Block Craft 3D  Building Simulator Games For Free\n",
      "Chess\n",
      "Puzzle Game\n",
      "Subway Surfers\n",
      "Pou\n",
      "Farming Simulator 18\n",
      "Dedi App 17\n",
      "Traffic Rider\n",
      "Beach Buggy Racing\n",
      "True Skate\n",
      "Stickman Skate Battle\n",
      "City Skater   Rule the Skate Park \n",
      "Stickman Soccer 2018\n",
      "Jet Car Stunts 2\n",
      "Dr  Driving 2\n",
      "Bike Race Free   Top Motorcycle Racing Games\n",
      "Traffic Racer\n",
      "FIFA Soccer\n",
      "Merge Plane   Click   Idle Tycoon\n",
      "Asphalt 8  Airborne\n",
      "Asphalt Nitro\n",
      "Real Chess\n",
      "Real Checkers\n",
      "Chess Online\n",
      "Russian Checkers\n",
      "Spanish Checkers\n",
      "English to Hindi Dictionary\n",
      "Brazilian Checkers\n",
      "eBook Reader   Your Free audio eBook Library\n",
      "Checkers\n",
      "Checkers Free\n",
      "Sudoku\n",
      "Tic Tac Toe Free\n",
      "English Hindi Dictionary\n",
      "Dictionary   Merriam Webster\n",
      "Pocket Thesaurus\n",
      "Pocket Quotations Premium\n",
      "Learner s Dictionary   English\n",
      "WordReference com dictionaries\n",
      "English French Thesaurus\n",
      "POC Bible  Malayalam \n",
      "Take Off\n",
      "Jesus Youth Prayer\n",
      "Jesus Youth\n",
      "Tecarta Bible\n",
      "Barnabodha\n",
      "Learn Hindi through English\n",
      "Learn Hindi through Tamil\n",
      "Learn Kannada through Tamil\n",
      "Bible\n",
      "Manorama Online News App   Malayala Manorama\n",
      "Malayala Manorama Calendar 2018\n",
      "Mathrubhumi Calendar 2018\n",
      "Gujarat Himachal Election 2017\n",
      "Malayalam News Live  Asianet News Live TV\n",
      "Ghar Baithe paise Kamaye   Earn Money Online\n",
      "Shabd Nidhi\n",
      "dict cc dictionary\n",
      "LEO dictionary\n",
      "German Dictionary Offline\n",
      "Spanish English Translator  Dictionary   Learning\n",
      "Learn Kannada through English\n",
      "Checkers Land Online\n",
      "TV Ecuador\n",
      "Acrobat Star Show   Show  em what you got \n",
      "Dictionary Linguee\n",
      "Doctor Fluff Pet Vet\n",
      "Operate Now  Animal Hospital\n",
      "Operate Now  Hospital\n",
      "Uphill Rush Water Park Racing\n",
      "NBA LIVE Mobile Basketball\n",
      "NBA App\n",
      "Basketball NBA Live Scores  Stats  Schedules  2019\n",
      "NBAmoji\n",
      "NBA AR Basketball  Augmented Reality Shot   Portal\n",
      "Indic Keyboard Swalekh Flip\n",
      "Crossy Road\n",
      "Rise Up\n",
      "Racing in Car\n",
      "Pet World   My animal shelter\n",
      "English Marathi Dictionary\n",
      "English Bangla Dictionary\n",
      "English To Bangla Dictionary\n",
      "Wings on Fire   Endless Flight\n",
      "Manorama Calendar 2018\n",
      "Star Wars   KOTOR\n",
      "Hindi Keyboard\n",
      "Skateboard Party 3 Pro\n",
      "Skateboard Party 3\n",
      "Farm Heroes Saga\n",
      "Asphalt 9  Legends   2018 s New Arcade Racing Game\n",
      "Cluefinder\n",
      "Knower Nikhil   Question papers   Free jobs alert\n",
      "Duolingo  Learn Languages Free\n",
      "8 Ball Pool\n",
      "Car Driving School Simulator\n",
      "Real Tractor Farming\n",
      "Full screen incoming caller\n",
      "Bangla Dictionary\n"
     ]
    }
   ],
   "source": [
    "# We choose PorterSteammer for stem \n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "def pre_process(content):\n",
    "    #print(content)\n",
    "    \n",
    "    #remove non alpha-numeric character\n",
    "    content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "    \n",
    "    #Lowercase\n",
    "    content = content.lower()\n",
    "\n",
    "    #We can use tolenize function - same result\n",
    "    words = nltk.word_tokenize(content)\n",
    "    \n",
    "    #Remove stopwords\n",
    "    meanningful_word = [word for word in words if word not in stop]\n",
    "\n",
    "    #Stem\n",
    "    stems = []\n",
    "    for word in meanningful_word:\n",
    "        stem = porter.stem(word)\n",
    "        stems.append(stem)\n",
    "    #print(stems)\n",
    "\n",
    "    content = ' '.join(stems)\n",
    "    return(content)\n",
    "    \n",
    "\n",
    "print('Here is the list of apps that cleaned')\n",
    "for app_name in files:\n",
    "    #print(app_name)\n",
    "    with open(app_name, 'r+') as file:\n",
    "        content = file.read()\n",
    "        text = (pre_process(content))\n",
    "        file.truncate()\n",
    "        file.seek(0)\n",
    "        print(app_name)\n",
    "        file.write(text)\n",
    "        file.close()\n",
    "        #print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...)Compute tdidf \n",
    "eg. Using functions from __[scikit-learn module](http://scikit-learn.org/stable/modules/classes.html)__. TfidfVectorizer is used for converting a collection of raw documents to a matrix of TF-IDF features.\n",
    "#### You can also build the tfidf matrix with other library or your own algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4109)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transvector = TfidfVectorizer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# scan all documents and take the text to make a corpus\n",
    "for file in files: \n",
    "    with open(file, 'r') as f:\n",
    "        corpus.append(f.readline().strip())\n",
    "#print(corpus)\n",
    "\n",
    "#Calculate\n",
    "tfidf1 = transvector.fit_transform(corpus)\n",
    "tfidf_matrix = tfidf1.toarray()\n",
    "tfidf_matrix.shape\n",
    "#print(tfidf_matrix)\n",
    "#print(transvector.get_feature_names())\n",
    "#print(transvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Process\n",
    "\n",
    "eg. \"Dragon, Control, hero, running\"\n",
    "\n",
    "eg. \"The hero controls the dragon to run.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#here is the query process function\n",
    "def query_process(query):\n",
    "    #clean the query, like clean the descriptions\n",
    "    query = pre_process(query)\n",
    "    #print(query)\n",
    "    query_word = query.split()\n",
    "    \n",
    "    #Calculating\n",
    "    query = transvector.transform(list(query_word)).toarray()\n",
    "    similarity = cosine_similarity(tfidf_matrix, query)\n",
    "    #print(similarity)\n",
    "    \n",
    "    simi_average = []\n",
    "    index = 0\n",
    "    \n",
    "    for doc in similarity:\n",
    "        value = sum(doc)/4\n",
    "        simi_average.append(value)\n",
    "        \n",
    "    top3 = sorted(zip(simi_average, files), reverse=True)[:3]\n",
    "\n",
    "    #print(index)\n",
    "    result = pd.DataFrame(np.array(top3).reshape(3,2), columns=[\"Average similarity\", \"Apps name\"])\n",
    "    return(result)\n",
    "\n",
    "#query_process('Dragon, Control, hero, running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Apps name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09442785765643148</td>\n",
       "      <td>Farm Heroes Saga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052329419449271726</td>\n",
       "      <td>Rise Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03752798900373222</td>\n",
       "      <td>Star Wars   KOTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Similarity          Apps name\n",
       "0   0.09442785765643148   Farm Heroes Saga\n",
       "1  0.052329419449271726            Rise Up\n",
       "2   0.03752798900373222  Star Wars   KOTOR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_process('Dragon, Control, hero, running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Apps name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09442785765643148</td>\n",
       "      <td>Farm Heroes Saga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052329419449271726</td>\n",
       "      <td>Rise Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03752798900373222</td>\n",
       "      <td>Star Wars   KOTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Similarity          Apps name\n",
       "0   0.09442785765643148   Farm Heroes Saga\n",
       "1  0.052329419449271726            Rise Up\n",
       "2   0.03752798900373222  Star Wars   KOTOR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_process('The hero controls the dragon to run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Apps name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05189540879338904</td>\n",
       "      <td>Bike Race Free   Top Motorcycle Racing Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04154004047104521</td>\n",
       "      <td>Chess Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040371236586411424</td>\n",
       "      <td>8 Ball Pool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Similarity                                     Apps name\n",
       "0   0.05189540879338904  Bike Race Free   Top Motorcycle Racing Games\n",
       "1   0.04154004047104521                                  Chess Online\n",
       "2  0.040371236586411424                                   8 Ball Pool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_process('playing music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
